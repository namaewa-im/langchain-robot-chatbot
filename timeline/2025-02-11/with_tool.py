import os
import openai
import nltk
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from langchain.tools import tool
from pydantic import BaseModel
from deep_translator import GoogleTranslator
from nltk.sentiment import SentimentIntensityAnalyzer

# 1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# 2ï¸âƒ£ LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4", openai_api_key=openai.api_key)

# 3ï¸âƒ£ ìƒíƒœ ì •ì˜
class TaskState(BaseModel):
    user_input: str = ""
    parsed_task: str = ""
    task_result: str = ""
    error: str = ""
    end: bool = False  # ì¢…ë£Œ ì—¬ë¶€ í™•ì¸

# 4ï¸âƒ£ ë””ë²„ê¹…ìš© ì¶œë ¥ í•¨ìˆ˜
def print_state(node_name, state: TaskState):
    print(f"\nğŸŸ¢ í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œ: {node_name}")
    print(f"ğŸ”¹ State: {state.model_dump()}\n")

# 5ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ ë…¸ë“œ
def get_user_input(state: TaskState):
    print_state("get_user_input", state)
    user_input = input("ì‚¬ìš©ì ì…ë ¥: ").strip().lower()

    if user_input in ["ê·¸ë§Œ", "ì¢…ë£Œ", "ë", "quit"]:
        return {"end": True}

    return {"user_input": user_input, "end": False}

# 6ï¸âƒ£ LLMì„ í†µí•´ ì…ë ¥ì„ íŒŒì‹±í•˜ëŠ” ë…¸ë“œ
def parse_task(state: TaskState):
    print_state("parse_task", state)
    if state.end:  # ì‚¬ìš©ìê°€ ì¢…ë£Œ ì˜ë„ë¥¼ ë³´ì˜€ì„ ê²½ìš° ì¢…ë£Œ
        return {"parsed_task": "ì¢…ë£Œ"}

    prompt = f"ë‹¤ìŒ ì…ë ¥ì—ì„œ ìˆ˜í–‰í•  íƒœìŠ¤í¬ë¥¼ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œ ì§€ì •í•˜ì„¸ìš” (ë²ˆì—­, ìš”ì•½, ë¶„ì„ ì¤‘ í•˜ë‚˜): {state.user_input}"
    response = llm([HumanMessage(content=prompt)]).content.strip().lower()

    if response not in ["ë²ˆì—­", "ìš”ì•½", "ë¶„ì„"]:
        return {"error": "ì˜¬ë°”ë¥¸ íƒœìŠ¤í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.", "parsed_task": ""}
    
    return {"parsed_task": response, "error": ""}

# 7ï¸âƒ£ Taskë³„ Tool ì •ì˜
# nltk.download("vader_lexicon")  # ê°ì • ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
sia = SentimentIntensityAnalyzer()

@tool
def translate_tool(text: str, target_lang: str = "en") -> str:
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” íˆ´"""
    try:
        translated_text = GoogleTranslator(source='auto', target=target_lang).translate(text)
        return f"ğŸ”  ë²ˆì—­ ê²°ê³¼: {translated_text}"
    except Exception as e:
        return f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {str(e)}"

@tool
def summarize_tool(text: str) -> str:
    """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” íˆ´"""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "system", "content": "You are a helpful assistant that summarizes text."},
                      {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ ì§§ê²Œ ìš”ì•½í•´ì¤˜: {text}"}]
        )
        summary = response["choices"][0]["message"]["content"]
        return f"ğŸ“„ ìš”ì•½ ê²°ê³¼: {summary}"
    except Exception as e:
        return f"âŒ ìš”ì•½ ì˜¤ë¥˜: {str(e)}"

@tool
def analyze_tool(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•œ í›„ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # 1ï¸âƒ£ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
        translated_text = GoogleTranslator(source='auto', target='en').translate(text)

        # 2ï¸âƒ£ NLTK VADER ê°ì • ë¶„ì„ ìˆ˜í–‰
        sentiment_scores = sia.polarity_scores(translated_text)
        compound_score = sentiment_scores["compound"]

        # 3ï¸âƒ£ ê°ì • ë¶„ì„ ê²°ê³¼ ê²°ì •
        if compound_score > 0.05:
            sentiment_label = "ê¸ì •ì  ğŸ˜€"
        elif compound_score < -0.05:
            sentiment_label = "ë¶€ì •ì  ğŸ˜"
        else:
            sentiment_label = "ì¤‘ë¦½ì  ğŸ˜"

        return f"ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼: {sentiment_label} (ì ìˆ˜: {compound_score})"
    
    except Exception as e:
        return f"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

# 8ï¸âƒ£ ì˜¤ë¥˜ ì²˜ë¦¬ ë…¸ë“œ
def handle_error(state: TaskState):
    print_state("handle_error", state)
    return {"task_result": state.error}

# ğŸ”Ÿ ì¢…ë£Œ ë…¸ë“œ
def end_node(state: TaskState):
    print_state("end_node", state)
    return {"task_result": "ğŸ›‘ ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}

# 1ï¸âƒ£1ï¸âƒ£ Task ìˆ˜í–‰ (Tool ì‹¤í–‰)
def execute_task(state: TaskState):
    print_state("execute_task", state)

    task_mapping = {
        "ë²ˆì—­": translate_tool,
        "ìš”ì•½": summarize_tool,
        "ë¶„ì„": analyze_tool
    }

    tool_function = task_mapping.get(state.parsed_task)
    
    if tool_function:
        result = tool_function(state.user_input)
        return {"task_result": result}
    else:
        return {"error": "âŒ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”."}

# 1ï¸âƒ£2ï¸âƒ£ ì¡°ê±´ë¶€ Edge ì„¤ì •
def task_selector(state: TaskState):
    if state.end:
        return "end_node"
    if state.error:
        return "error_handler"
    return "execute_task"

# 1ï¸âƒ£3ï¸âƒ£ ê·¸ë˜í”„ êµ¬ì¡° ì„¤ì •
graph = StateGraph(TaskState)
graph.add_node("get_user_input", get_user_input)
graph.add_node("parse_task", parse_task)
graph.add_node("execute_task", execute_task)
graph.add_node("error_handler", handle_error)
graph.add_node("end_node", end_node)

graph.add_edge("get_user_input", "parse_task")
graph.add_conditional_edges("parse_task", task_selector)
graph.add_edge("execute_task", "get_user_input")
graph.add_edge("error_handler", "get_user_input")

# 1ï¸âƒ£4ï¸âƒ£ ì‹œì‘ ë° ì¢…ë£Œ ì§€ì  ì„¤ì •
graph.set_entry_point("get_user_input")
graph.set_finish_point("end_node")

# 1ï¸âƒ£5ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰ (ë¬´í•œ ë£¨í”„ ê°€ëŠ¥)
app = graph.compile()
state = TaskState()

while True:
    state = app.invoke(state)  # `state`ëŠ” ì´ì œ `dict` í˜•íƒœì„
    print(f"âœ… ì‹¤í–‰ ê²°ê³¼: {state.get('task_result', '')}\n")  # `.get()`ì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
    if state.get("end", False):  # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        break
