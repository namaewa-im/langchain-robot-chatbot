import os
from dotenv import load_dotenv

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

##----------------------------------------------------
## NLTK VADER ê°ì • ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ - í•œêµ­ì–´ëŠ” compound scoreê°€ ì˜ ì•ˆë‚˜ì˜´
##----------------------------------------------------


import nltk
from deep_translator import GoogleTranslator
from nltk.sentiment import SentimentIntensityAnalyzer
import openai

# 1ï¸âƒ£ NLTK VADER ê°ì • ë¶„ì„ê¸° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ ì‹¤í–‰ í•„ìš”)
nltk.download('vader_lexicon')

# 2ï¸âƒ£ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
sia = SentimentIntensityAnalyzer()

# 4ï¸âƒ£ ê°ì • ë¶„ì„ í•¨ìˆ˜ (NLTK + OpenAI GPT ì‚¬ìš©)
def analyze_sentiment(text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•œ í›„ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # 1ï¸âƒ£ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
        translated_text = GoogleTranslator(source='auto', target='en').translate(text)

        # 2ï¸âƒ£ NLTK VADER ê°ì • ë¶„ì„ ìˆ˜í–‰
        sentiment_scores = sia.polarity_scores(translated_text)
        compound_score = sentiment_scores["compound"]

        # 3ï¸âƒ£ ê°ì • ë¶„ì„ ê²°ê³¼ ê²°ì •
        if compound_score > 0.05:
            sentiment_label = "ê¸ì •ì  ğŸ˜€"
        elif compound_score < -0.05:
            sentiment_label = "ë¶€ì •ì  ğŸ˜"
        else:
            sentiment_label = "ì¤‘ë¦½ì  ğŸ˜"

        return f"ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼: {sentiment_label} (ì ìˆ˜: {compound_score})"
    
    except Exception as e:
        return f"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

# 5ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    sample_texts = [
        "ì˜¤ëŠ˜ í•˜ë£¨ ì •ë§ ìµœì•…ì´ì—ˆì–´. ë„ˆë¬´ í˜ë“¤ë‹¤.",
        "so sad and lonely",
        "ì´ ì˜í™”ëŠ” ë‚´ ì¸ìƒ ìµœê³ ì˜ ì˜í™”ì•¼! ë„ˆë¬´ ê°ë™ì ì´ì•¼.",
        "its interesting",
        "ê·¸ëƒ¥ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´."
    ]
    
    for text in sample_texts:
        print(f"ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸: {text}")
        print(analyze_sentiment(text))
        print("-" * 50)
